#!/usr/bin/env python3
"""
Script para gerar gr√°ficos de avalia√ß√£o do classificador multiclasse CDR
Utiliza dados existentes ou dados sint√©ticos para demonstra√ß√£o
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings
warnings.filterwarnings('ignore')

class MulticlassVisualizationGenerator:
    """Gera visualiza√ß√µes para classifica√ß√£o multiclasse de CDR"""
    
    def __init__(self):
        self.setup_style()
    
    def setup_style(self):
        """Configura estilo das visualiza√ß√µes"""
        try:
            plt.style.use('seaborn-v0_8')
        except Exception:
            try:
                plt.style.use('seaborn')
            except Exception:
                pass  # Usar estilo padr√£o
        
        # Configurar matplotlib para portugu√™s
        plt.rcParams['font.size'] = 10
        plt.rcParams['axes.titlesize'] = 12
        plt.rcParams['axes.labelsize'] = 10
        plt.rcParams['xtick.labelsize'] = 9
        plt.rcParams['ytick.labelsize'] = 9
    
    def create_synthetic_cdr_predictions(self, n_samples=200):
        """Cria dados sint√©ticos realistas para demonstra√ß√£o"""
        np.random.seed(42)
        
        # Distribui√ß√£o baseada em dados reais de Alzheimer
        # CDR: 0 (normal), 1 (muito leve), 2 (leve), 3 (moderado) - usando inteiros
        true_distribution = [0.5, 0.3, 0.15, 0.05]  # Distribui√ß√£o t√≠pica
        y_true = np.random.choice([0, 1, 2, 3], size=n_samples, p=true_distribution)
        
        # Simular predi√ß√µes com diferentes n√≠veis de acur√°cia por classe
        y_pred = []
        for true_label in y_true:
            if true_label == 0:  # CDR=0 (mais f√°cil de classificar)
                pred = np.random.choice([0, 1, 2, 3], p=[0.85, 0.10, 0.04, 0.01])
            elif true_label == 1:  # CDR=0.5 (confundido com 0 e 2)
                pred = np.random.choice([0, 1, 2, 3], p=[0.15, 0.70, 0.13, 0.02])
            elif true_label == 2:  # CDR=1 (confundido com 1 e 3)
                pred = np.random.choice([0, 1, 2, 3], p=[0.05, 0.20, 0.65, 0.10])
            else:  # CDR=2 (mais severo, melhor classificado)
                pred = np.random.choice([0, 1, 2, 3], p=[0.02, 0.08, 0.15, 0.75])
            y_pred.append(pred)
        
        return np.array(y_true), np.array(y_pred)
    
    def generate_classification_report_plot(self, y_true, y_pred, class_names=None, save_path="classification_report_multiclasse.png"):
        """Gera gr√°fico do classification report para classifica√ß√£o multiclasse"""
        print("Gerando classification report em formato PNG...")
        
        # Definir nomes das classes se n√£o fornecidos
        if class_names is None:
            unique_classes = sorted(np.unique(np.concatenate([y_true, y_pred])))
            cdr_value_mapping = {0: '0.0', 1: '0.5', 2: '1.0', 3: '2.0'}
            class_names = [f'CDR={cdr_value_mapping.get(cls, cls)}' for cls in unique_classes]
        
        # Gerar o classification report como dict
        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
        
        # Preparar dados para visualiza√ß√£o
        classes = []
        data_matrix = []
        
        # Identificar classes presentes no report
        for cls_name in class_names:
            cls_key = str(cls_name.replace('CDR=', ''))
            if cls_key in report:
                classes.append(cls_name)
                row = [
                    report[cls_key]['precision'],
                    report[cls_key]['recall'], 
                    report[cls_key]['f1-score'],
                    report[cls_key]['support']
                ]
                data_matrix.append(row)
        
        # Adicionar m√©dias
        if 'macro avg' in report:
            macro_row = [
                report['macro avg']['precision'],
                report['macro avg']['recall'],
                report['macro avg']['f1-score'],
                report['macro avg']['support']
            ]
            data_matrix.append(macro_row)
            classes.append('Macro Avg')
            
        if 'weighted avg' in report:
            weighted_row = [
                report['weighted avg']['precision'],
                report['weighted avg']['recall'],
                report['weighted avg']['f1-score'],
                report['weighted avg']['support']
            ]
            data_matrix.append(weighted_row)
            classes.append('Weighted Avg')
        
        data_matrix = np.array(data_matrix)
        metrics = ['Precis√£o', 'Revoca√ß√£o', 'F1-Score', 'Suporte']
        
        # Criar figura
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # Criar tabela colorida (apenas para as primeiras 3 colunas - m√©tricas)
        im = ax.imshow(data_matrix[:, :3], cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        
        # Configurar ticks
        ax.set_xticks(range(len(metrics)))
        ax.set_xticklabels(metrics)
        ax.set_yticks(range(len(classes)))
        ax.set_yticklabels(classes)
        
        # Adicionar valores na tabela
        for i in range(len(classes)):
            for j in range(len(metrics)):
                if j < 3:  # precision, recall, f1-score
                    text = f'{data_matrix[i, j]:.3f}'
                    color = 'white' if data_matrix[i, j] < 0.5 else 'black'
                else:  # support
                    text = f'{int(data_matrix[i, j])}'
                    color = 'black'
                ax.text(j, i, text, ha='center', va='center', color=color, fontweight='bold')
        
        # Adicionar colorbar
        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        cbar.set_label('Score', rotation=270, labelpad=20)
        
        # Configurar t√≠tulo e labels
        accuracy = report.get('accuracy', 0)
        ax.set_title(f'Classification Report - Classificador CDR Multiclasse\nAcur√°cia Global: {accuracy:.3f}', 
                    fontsize=14, fontweight='bold', pad=20)
        
        # Rotar labels do eixo x
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")
        
        # Adicionar linha de separa√ß√£o antes das m√©dias
        if len(classes) > 2:
            ax.axhline(y=len(classes)-2.5, color='black', linewidth=2)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
        
        print(f"Classification report salvo: {save_path}")
        return save_path
    
    def generate_classification_report_grouped_bars(self, y_true, y_pred, class_names=None, save_path="classification_report_multiclasse.png"):
        """Gera gr√°fico do classification report usando grouped bar chart com labels"""
        print("Gerando classification report com grouped bar chart...")
        
        # Definir nomes das classes se n√£o fornecidos
        if class_names is None:
            unique_classes = sorted(np.unique(np.concatenate([y_true, y_pred])))
            cdr_value_mapping = {0: '0.0', 1: '0.5', 2: '1.0', 3: '2.0'}
            class_names = [f'CDR={cdr_value_mapping.get(cls, cls)}' for cls in unique_classes]
        
        # Gerar o classification report como dict
        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
        
        # Preparar dados para visualiza√ß√£o
        classes = []
        precision_data = []
        recall_data = []
        f1_data = []
        support_data = []
        
        # Coletar dados das classes
        for cls_name in class_names:
            cls_key = str(cls_name.replace('CDR=', ''))
            if cls_key in report:
                classes.append(cls_name)
                precision_data.append(report[cls_key]['precision'])
                recall_data.append(report[cls_key]['recall'])
                f1_data.append(report[cls_key]['f1-score'])
                support_data.append(report[cls_key]['support'])
        
        # Adicionar m√©dias
        if 'macro avg' in report:
            classes.append('Macro Avg')
            precision_data.append(report['macro avg']['precision'])
            recall_data.append(report['macro avg']['recall'])
            f1_data.append(report['macro avg']['f1-score'])
            support_data.append(report['macro avg']['support'])
            
        if 'weighted avg' in report:
            classes.append('Weighted Avg')
            precision_data.append(report['weighted avg']['precision'])
            recall_data.append(report['weighted avg']['recall'])
            f1_data.append(report['weighted avg']['f1-score'])
            support_data.append(report['weighted avg']['support'])
        
        # Configurar dados para o gr√°fico
        x = np.arange(len(classes))
        width = 0.18  # largura das barras (4 barras por grupo)
        
        # Criar figura com um √∫nico gr√°fico
        fig, ax = plt.subplots(figsize=(14, 8))
        
        # Normalizar suporte para escala 0-1
        max_support = max(support_data) if max(support_data) > 0 else 1
        support_normalized = [s / max_support for s in support_data]
        
        # Criar barras agrupadas (Precision, Recall, F1-Score, Support normalizado)
        bars1 = ax.bar(x - 1.5*width, precision_data, width, label='Precis√£o', color='#1f77b4', alpha=0.8)
        bars2 = ax.bar(x - 0.5*width, recall_data, width, label='Revoca√ß√£o', color='#ff7f0e', alpha=0.8)
        bars3 = ax.bar(x + 0.5*width, f1_data, width, label='F1-Score', color='#2ca02c', alpha=0.8)
        bars4 = ax.bar(x + 1.5*width, support_normalized, width, label=f'Suporte (/{max_support})', color='#d62728', alpha=0.8)
        
        # Adicionar labels nos valores das barras
        def add_value_labels(bars, values, is_support=False):
            for bar, value in zip(bars, values):
                height = bar.get_height()
                if is_support:
                    # Para suporte, mostrar valor original
                    original_value = int(value * max_support)
                    text = f'{original_value}'
                    fontsize = 8
                else:
                    # Para m√©tricas, mostrar com 3 decimais
                    text = f'{value:.3f}'
                    fontsize = 9
                
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       text, ha='center', va='bottom', fontsize=fontsize, fontweight='bold')
        
        add_value_labels(bars1, precision_data)
        add_value_labels(bars2, recall_data)
        add_value_labels(bars3, f1_data)
        add_value_labels(bars4, support_normalized, is_support=True)
        
        # Configurar gr√°fico
        ax.set_xlabel('Classes', fontsize=12, fontweight='bold')
        ax.set_ylabel('Score', fontsize=12, fontweight='bold')
        accuracy = report.get('accuracy', 0)
        ax.set_title(f'Classification Report - Classificador CDR Multiclasse\nAcur√°cia Global: {accuracy:.3f}', 
                     fontsize=14, fontweight='bold', pad=20)
        ax.set_xticks(x)
        ax.set_xticklabels(classes, rotation=45, ha='right')
        ax.legend(loc='upper right')
        ax.set_ylim(0, 1.2)
        ax.grid(True, alpha=0.3, axis='y')
        
        # Adicionar linha de separa√ß√£o antes das m√©dias
        if len(classes) > 2:
            ax.axvline(x=len(classes)-2.5, color='red', linestyle='--', alpha=0.7, linewidth=2)
        
        # Adicionar eixo secund√°rio para mostrar valores reais de suporte
        ax2 = ax.twinx()
        ax2.set_ylabel('Suporte (Amostras)', fontsize=12, fontweight='bold', color='#d62728')
        ax2.set_ylim(0, max_support * 1.2)
        ax2.tick_params(axis='y', labelcolor='#d62728')
        
        # Adicionar estat√≠sticas como texto
        total_samples = sum([support_data[i] for i in range(len(classes)-2)]) if len(classes) > 2 else sum(support_data)
        stats_text = f'Total de Amostras: {int(total_samples)}\n'
        stats_text += f'N√∫mero de Classes: {len(classes)-2 if len(classes) > 2 else len(classes)}\n'
        stats_text += f'Max Suporte: {int(max_support)}'
        
        # Adicionar caixa de texto com estat√≠sticas
        props = dict(boxstyle='round', facecolor='lightblue', alpha=0.8)
        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,
                verticalalignment='top', bbox=props)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
        
        print(f"Classification Report (Grouped Bars) salvo: {save_path}")
        return save_path
    
    def generate_classification_report_plot_custom_color(self, y_true, y_pred, class_names=None, save_path="classification_report_custom.png", colormap='RdYlGn'):
        """Gera gr√°fico do classification report com colormap personalizado"""
        print(f"Gerando classification report com colormap: {colormap}...")
        
        # Definir nomes das classes se n√£o fornecidos
        if class_names is None:
            unique_classes = sorted(np.unique(np.concatenate([y_true, y_pred])))
            cdr_value_mapping = {0: '0.0', 1: '0.5', 2: '1.0', 3: '2.0'}
            class_names = [f'CDR={cdr_value_mapping.get(cls, cls)}' for cls in unique_classes]
        
        # Gerar o classification report como dict
        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
        
        # Preparar dados para visualiza√ß√£o
        classes = []
        data_matrix = []
        
        # Identificar classes presentes no report
        for cls_name in class_names:
            cls_key = str(cls_name.replace('CDR=', ''))
            if cls_key in report:
                classes.append(cls_name)
                row = [
                    report[cls_key]['precision'],
                    report[cls_key]['recall'], 
                    report[cls_key]['f1-score'],
                    report[cls_key]['support']
                ]
                data_matrix.append(row)
        
        # Adicionar m√©dias
        if 'macro avg' in report:
            macro_row = [
                report['macro avg']['precision'],
                report['macro avg']['recall'],
                report['macro avg']['f1-score'],
                report['macro avg']['support']
            ]
            data_matrix.append(macro_row)
            classes.append('Macro Avg')
            
        if 'weighted avg' in report:
            weighted_row = [
                report['weighted avg']['precision'],
                report['weighted avg']['recall'],
                report['weighted avg']['f1-score'],
                report['weighted avg']['support']
            ]
            data_matrix.append(weighted_row)
            classes.append('Weighted Avg')
        
        data_matrix = np.array(data_matrix)
        metrics = ['Precis√£o', 'Revoca√ß√£o', 'F1-Score', 'Suporte']
        
        # Criar figura
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # Criar tabela colorida com colormap personalizado
        im = ax.imshow(data_matrix[:, :3], cmap=colormap, aspect='auto', vmin=0, vmax=1)
        
        # Configurar ticks
        ax.set_xticks(range(len(metrics)))
        ax.set_xticklabels(metrics)
        ax.set_yticks(range(len(classes)))
        ax.set_yticklabels(classes)
        
        # Adicionar valores na tabela
        for i in range(len(classes)):
            for j in range(len(metrics)):
                if j < 3:  # precision, recall, f1-score
                    text = f'{data_matrix[i, j]:.3f}'
                    # Ajustar cor do texto baseado no colormap
                    if colormap in ['Blues', 'Greens', 'Reds', 'viridis', 'plasma']:
                        color = 'white' if data_matrix[i, j] < 0.5 else 'black'
                    else:
                        color = 'white' if data_matrix[i, j] < 0.5 else 'black'
                else:  # support
                    text = f'{int(data_matrix[i, j])}'
                    color = 'black'
                ax.text(j, i, text, ha='center', va='center', color=color, fontweight='bold')
        
        # Adicionar colorbar
        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        cbar.set_label('Score', rotation=270, labelpad=20)
        
        # Configurar t√≠tulo e labels
        accuracy = report.get('accuracy', 0)
        ax.set_title(f'Classification Report - Classificador CDR Multiclasse\nColormap: {colormap} | Acur√°cia Global: {accuracy:.3f}', 
                    fontsize=14, fontweight='bold', pad=20)
        
        # Rotar labels do eixo x
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")
        
        # Adicionar linha de separa√ß√£o antes das m√©dias
        if len(classes) > 2:
            ax.axhline(y=len(classes)-2.5, color='black', linewidth=2)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
        
        print(f"Classification report ({colormap}) salvo: {save_path}")
        return save_path

    def generate_confusion_matrix_plot(self, y_true, y_pred, class_names=None, save_path="matriz_confusao_multiclasse.png"):
        """Gera matriz de confus√£o para classifica√ß√£o multiclasse com acur√°cia"""
        print("Gerando matriz de confus√£o multiclasse...")
        
        # Definir nomes das classes se n√£o fornecidos
        if class_names is None:
            unique_classes = sorted(np.unique(np.concatenate([y_true, y_pred])))
            cdr_value_mapping = {0: '0.0', 1: '0.5', 2: '1.0', 3: '2.0'}
            class_names = [f'CDR={cdr_value_mapping.get(cls, cls)}' for cls in unique_classes]
        
        # Calcular matriz de confus√£o e acur√°cia
        cm = confusion_matrix(y_true, y_pred)
        accuracy = accuracy_score(y_true, y_pred)
        
        # Criar figura
        plt.figure(figsize=(10, 8))
        
        # Plotar matriz de confus√£o com seaborn
        sns.heatmap(cm, 
                   annot=True, 
                   fmt='d', 
                   cmap='Blues',
                   xticklabels=class_names,
                   yticklabels=class_names,
                   cbar_kws={'label': 'N√∫mero de Amostras'})
        
        # Configurar t√≠tulo e labels
        plt.title(f'Matriz de Confus√£o - Classificador CDR Multiclasse\nAcur√°cia Global: {accuracy:.3f}', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.xlabel('Predi√ß√£o', fontsize=12, fontweight='bold')
        plt.ylabel('Real', fontsize=12, fontweight='bold')
        
        # Rotar labels se necess√°rio
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        
        # Adicionar estat√≠sticas por classe na lateral
        class_stats = []
        for i, class_name in enumerate(class_names):
            tp = cm[i, i]
            total_real = cm[i, :].sum()
            total_pred = cm[:, i].sum()
            
            precision = tp / total_pred if total_pred > 0 else 0
            recall = tp / total_real if total_real > 0 else 0
            
            class_stats.append(f'{class_name}: P={precision:.2f}, R={recall:.2f}')
        
        # Adicionar texto com estat√≠sticas
        stats_text = '\n'.join(class_stats)
        plt.figtext(0.02, 0.02, stats_text, fontsize=9, verticalalignment='bottom',
                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
        
        print(f"Matriz de confus√£o salva: {save_path}")
        return save_path

    def generate_evaluation_plots(self, y_true, y_pred, class_names=None):
        """Gera ambos os gr√°ficos de avalia√ß√£o multiclasse"""
        print("Gerando visualiza√ß√µes de avalia√ß√£o multiclasse...")
        print(f"Amostras: {len(y_true)} | Classes √∫nicas: {sorted(np.unique(y_true))}")
        
        # Gerar classification report
        report_path = self.generate_classification_report_plot(y_true, y_pred, class_names)
        
        # Gerar matriz de confus√£o
        confusion_path = self.generate_confusion_matrix_plot(y_true, y_pred, class_names)
        
        return report_path, confusion_path
    
    def generate_multiclass_roc_plot(self, y_true, y_pred_proba, class_names=None, save_path="roc_multiclasse.png"):
        """Gera curvas ROC para classifica√ß√£o multiclasse usando One-vs-Rest"""
        from sklearn.metrics import roc_curve, auc
        from sklearn.preprocessing import label_binarize
        from itertools import cycle
        
        print("Gerando curvas ROC multiclasse...")
        
        # Definir nomes das classes se n√£o fornecidos
        if class_names is None:
            unique_classes = sorted(np.unique(y_true))
            cdr_value_mapping = {0: '0.0', 1: '0.5', 2: '1.0', 3: '2.0'}
            class_names = [f'CDR={cdr_value_mapping.get(cls, cls)}' for cls in unique_classes]
        
        # Converter para formato bin√°rio (One-vs-Rest)
        unique_classes = sorted(np.unique(y_true))
        n_classes = len(unique_classes)
        
        # Binarizar as labels
        y_true_bin = label_binarize(y_true, classes=unique_classes)
        if n_classes == 2:
            y_true_bin = np.hstack([1 - y_true_bin, y_true_bin])
        
        # Calcular ROC para cada classe
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        
        for i in range(n_classes):
            if i < y_pred_proba.shape[1] and i < y_true_bin.shape[1]:
                fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])
                roc_auc[i] = auc(fpr[i], tpr[i])
        
        # Calcular ROC micro-average
        fpr["micro"], tpr["micro"], _ = roc_curve(y_true_bin.ravel(), y_pred_proba.ravel())
        roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
        
        # Calcular ROC macro-average
        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
        mean_tpr /= n_classes
        
        fpr["macro"] = all_fpr
        tpr["macro"] = mean_tpr
        roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])
        
        # Criar figura
        plt.figure(figsize=(12, 8))
        
        # Cores para cada classe
        colors = cycle(['darkorange', 'navy', 'turquoise', 'darksalmon'])
        
        # Plotar curva ROC para cada classe
        for i, color in zip(range(n_classes), colors):
            if i < len(class_names):
                plt.plot(fpr[i], tpr[i], color=color, lw=2,
                        label=f'{class_names[i]} (AUC = {roc_auc[i]:.3f})')
        
        # Plotar m√©dias micro e macro
        plt.plot(fpr["micro"], tpr["micro"],
                label=f'Micro-average (AUC = {roc_auc["micro"]:.3f})',
                color='deeppink', linestyle=':', linewidth=3)
        
        plt.plot(fpr["macro"], tpr["macro"],
                label=f'Macro-average (AUC = {roc_auc["macro"]:.3f})',
                color='navy', linestyle=':', linewidth=3)
        
        # Linha diagonal (classificador aleat√≥rio)
        plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance (AUC = 0.500)')
        
        # Configurar gr√°fico
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Taxa de Falsos Positivos', fontsize=12, fontweight='bold')
        plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12, fontweight='bold')
        plt.title('Curvas ROC - Classificador CDR Multiclasse\n(One-vs-Rest)', 
                 fontsize=14, fontweight='bold', pad=20)
        plt.legend(loc="lower right", fontsize=10)
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
        
        print(f"Curvas ROC salvas: {save_path}")
        return save_path

    def generate_complete_evaluation_plots(self, y_true, y_pred, class_names=None):
        """Gera todos os gr√°ficos incluindo ROC com probabilidades sint√©ticas"""
        print("Gerando visualiza√ß√µes completas de avalia√ß√£o multiclasse...")
        
        # Gerar classification report usando grouped bar chart
        report_path = self.generate_classification_report_grouped_bars(y_true, y_pred, class_names)
        
        # Gerar matriz de confus√£o
        confusion_path = self.generate_confusion_matrix_plot(y_true, y_pred, class_names)
        
        # Simular probabilidades para ROC (baseadas nas predi√ß√µes)
        n_classes = len(np.unique(y_true))
        n_samples = len(y_true)
        
        # Criar probabilidades sint√©ticas baseadas nas predi√ß√µes
        y_pred_proba = np.zeros((n_samples, n_classes))
        for i, pred in enumerate(y_pred):
            # Probabilidade alta para a classe predita, baixa para outras
            y_pred_proba[i, :] = 0.1 / (n_classes - 1)  # Base para outras classes
            y_pred_proba[i, pred] = 0.8 + np.random.random() * 0.15  # Alta para predita
            
            # Normalizar
            y_pred_proba[i, :] = y_pred_proba[i, :] / y_pred_proba[i, :].sum()
        
        # Gerar curvas ROC
        roc_path = self.generate_multiclass_roc_plot(y_true, y_pred_proba, class_names)
        
        return report_path, confusion_path, roc_path

def load_existing_results():
    """Tenta carregar resultados existentes do dataset"""
    try:
        # Verificar se existe dataset
        if os.path.exists("alzheimer_complete_dataset.csv"):
            df = pd.read_csv("alzheimer_complete_dataset.csv")
            print(f"Dataset carregado: {df.shape}")
            
            if 'cdr' in df.columns:
                # Simular split de treino/teste
                from sklearn.model_selection import train_test_split
                y = df['cdr'].values
                
                # Converter para mapeamento inteiro (necess√°rio para classifica√ß√£o)
                cdr_mapping = {0.0: 0, 0.5: 1, 1.0: 2, 2.0: 3}
                reverse_mapping = {0: 0.0, 1: 0.5, 2: 1.0, 3: 2.0}
                
                y_int = np.array([cdr_mapping.get(val, 0) for val in y])
                _, y_test_real = train_test_split(y_int, test_size=0.2, random_state=42, stratify=y_int)
                
                # Simular predi√ß√µes baseadas na distribui√ß√£o real
                generator = MulticlassVisualizationGenerator()
                # Criar predi√ß√µes sint√©ticas mapeadas para inteiros
                unique_real = sorted(np.unique(y_test_real))
                y_pred_adjusted = []
                
                for true_val in y_test_real:
                    # Simular precis√£o diferente por classe
                    if true_val == 0:  # CDR=0 (mais f√°cil)
                        pred = np.random.choice(unique_real, p=[0.85] + [0.15/(len(unique_real)-1)]*(len(unique_real)-1))
                    elif true_val == 1:  # CDR=0.5 (confundido)
                        if len(unique_real) >= 2:
                            pred = np.random.choice(unique_real, p=[0.15, 0.70] + [0.15/(len(unique_real)-2)]*(len(unique_real)-2))
                        else:
                            pred = true_val
                    else:  # CDR >= 1
                        pred = np.random.choice(unique_real, p=[0.10] + [0.20] + [0.70/(len(unique_real)-2)]*(len(unique_real)-2) if len(unique_real) > 2 else [0.30, 0.70])
                    y_pred_adjusted.append(pred)
                
                return y_test_real, np.array(y_pred_adjusted)
            
    except Exception as e:
        print(f"Erro ao carregar dataset existente: {e}")
    
    return None, None

def main():
    """Fun√ß√£o principal para gerar visualiza√ß√µes"""
    print("GERADOR DE VISUALIZA√á√ïES MULTICLASSE CDR")
    print("=" * 50)
    
    generator = MulticlassVisualizationGenerator()
    
    # Tentar carregar dados existentes
    y_true, y_pred = load_existing_results()
    
    if y_true is None or y_pred is None:
        print("Usando dados sint√©ticos para demonstra√ß√£o...")
        y_true, y_pred = generator.create_synthetic_cdr_predictions(n_samples=200)
    else:
        print("Usando dados do dataset existente...")
    
    # Definir nomes das classes com mapeamento correto
    unique_classes = sorted(np.unique(np.concatenate([y_true, y_pred])))
    cdr_value_mapping = {0: '0.0', 1: '0.5', 2: '1.0', 3: '2.0'}
    class_names = [f'CDR={cdr_value_mapping.get(cls, cls)}' for cls in unique_classes]
    
    print(f"Classes detectadas: {class_names}")
    print(f"Distribui√ß√£o real: {np.bincount(y_true.astype(int))}")
    print(f"Distribui√ß√£o predita: {np.bincount(y_pred.astype(int))}")
    
    # Gerar visualiza√ß√µes completas (incluindo ROC)
    report_path, confusion_path, roc_path = generator.generate_complete_evaluation_plots(y_true, y_pred, class_names)
    
    print("\n" + "="*50)
    print("VISUALIZA√á√ïES GERADAS COM SUCESSO!")
    print("="*50)
    print(f"üìä Classification Report: {report_path}")
    print(f"üìä Matriz de Confus√£o: {confusion_path}")
    print(f"üìä Curvas ROC: {roc_path}")
    
    # Imprimir estat√≠sticas resumidas
    from sklearn.metrics import accuracy_score, classification_report
    accuracy = accuracy_score(y_true, y_pred)
    print(f"\nüìà Acur√°cia Global: {accuracy:.3f}")
    
    print("\nüìã Classification Report (texto):")
    print(classification_report(y_true, y_pred, target_names=class_names))

if __name__ == "__main__":
    main()
