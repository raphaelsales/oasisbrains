#!/usr/bin/env python3
"""
Script de Teste para ConfiguraÃ§Ãµes GPU/CPU do Pipeline Alzheimer
Ãštil para verificar configuraÃ§Ãµes antes de executar o pipeline completo
"""

import tensorflow as tf
import numpy as np
import time

def test_gpu_configuration():
    """Testa configuraÃ§Ãµes de GPU e CPU"""
    print("ğŸ§ª TESTE DE CONFIGURAÃ‡ÃƒO GPU/CPU")
    print("=" * 40)
    
    # InformaÃ§Ãµes bÃ¡sicas
    print(f"ğŸ“¦ TensorFlow: {tf.__version__}")
    print(f"ğŸ NumPy: {np.__version__}")
    
    # Verificar GPUs
    gpus = tf.config.list_physical_devices('GPU')
    print(f"\nğŸ¯ GPUs fÃ­sicas detectadas: {len(gpus)}")
    
    if gpus:
        for i, gpu in enumerate(gpus):
            print(f"   GPU {i}: {gpu.name}")
            try:
                # Tentar configurar memÃ³ria
                tf.config.experimental.set_memory_growth(gpu, True)
                print(f"   âœ… MemÃ³ria configurada para {gpu.name}")
            except Exception as e:
                print(f"   âŒ Erro na configuraÃ§Ã£o: {e}")
    else:
        print("   âš ï¸  Nenhuma GPU detectada - usando CPU")
    
    # Verificar CUDA
    print(f"\nğŸ”¥ CUDA build: {tf.test.is_built_with_cuda()}")
    print(f"ğŸ”¥ GPU disponÃ­vel: {tf.test.is_gpu_available()}")
    
    # Teste de performance simples
    print("\nâš¡ TESTE DE PERFORMANCE:")
    print("-" * 25)
    
    # Teste CPU
    with tf.device('/CPU:0'):
        start_time = time.time()
        x = tf.random.normal([1000, 1000])
        y = tf.matmul(x, x)
        result_cpu = tf.reduce_sum(y)
        cpu_time = time.time() - start_time
        print(f"ğŸ–¥ï¸  CPU: {cpu_time:.4f}s")
    
    # Teste GPU (se disponÃ­vel)
    if gpus and tf.test.is_gpu_available():
        try:
            with tf.device('/GPU:0'):
                start_time = time.time()
                x = tf.random.normal([1000, 1000])
                y = tf.matmul(x, x)
                result_gpu = tf.reduce_sum(y)
                gpu_time = time.time() - start_time
                print(f"ğŸš€ GPU: {gpu_time:.4f}s")
                
                if cpu_time > 0:
                    speedup = cpu_time / gpu_time
                    print(f"âš¡ Speedup: {speedup:.2f}x")
        except Exception as e:
            print(f"âŒ Erro no teste GPU: {e}")
    
    # RecomendaÃ§Ãµes
    print("\nğŸ’¡ RECOMENDAÃ‡Ã•ES:")
    print("-" * 15)
    
    if not gpus:
        print("ğŸ”§ Para configurar GPU:")
        print("   1. Instale drivers NVIDIA adequados")
        print("   2. Instale CUDA e cuDNN")
        print("   3. Instale tensorflow[gpu]")
        print("   4. Reinicie o sistema")
    elif not tf.test.is_gpu_available():
        print("ğŸ”§ GPU detectada mas nÃ£o utilizÃ¡vel:")
        print("   1. Verifique drivers NVIDIA: nvidia-smi")
        print("   2. Verifique CUDA: nvcc --version")
        print("   3. Verifique compatibilidade TensorFlow-CUDA")
        print("   4. Reinicialize os drivers: sudo service nvidia-restart")
    else:
        print("âœ… GPU configurada corretamente!")
        print("ğŸš€ Pipeline otimizado para aceleraÃ§Ã£o GPU")
    
    # ConfiguraÃ§Ãµes recomendadas para CPU
    print("\nğŸ–¥ï¸  OTIMIZAÃ‡Ã•ES CPU (caso nÃ£o tenha GPU):")
    print("   - Use batch_size menor (16-32)")
    print("   - Reduza nÃºmero de camadas do modelo")
    print("   - Use mixed precision pode ajudar mesmo em CPU")
    print("   - Configure threads: export OMP_NUM_THREADS=4")

if __name__ == "__main__":
    test_gpu_configuration()
    print("\nğŸš€ Para executar o pipeline completo:")
    print("   python3 alzheimer_ai_pipeline.py") 