# ğŸ“Š GUIA TENSORBOARD - PIPELINE ALZHEIMER

## ğŸ” Como Acessar
```bash
# TensorBoard jÃ¡ estÃ¡ rodando em:
http://localhost:6006

# Ou inicie manualmente:
tensorboard --logdir=logs --host=0.0.0.0 --port=6006
```

## ğŸ“ˆ INTERPRETANDO AS MÃ‰TRICAS

### ğŸ¯ SCALARS (MÃ©tricas Principais)

#### **ğŸ“Š Loss (Perda)**
- **Training Loss**: Como o modelo estÃ¡ aprendendo
  - â¬‡ï¸ Deve diminuir ao longo das Ã©pocas
  - ğŸ“‰ Se aumenta = overfitting
  
- **Validation Loss**: GeneralizaÃ§Ã£o do modelo
  - â¬‡ï¸ Deve diminuir junto com training
  - âš ï¸ Se aumenta enquanto training diminui = overfitting

#### **ğŸ¯ Accuracy (PrecisÃ£o)**
- **Training Accuracy**: PrecisÃ£o nos dados de treino
  - â¬†ï¸ Deve aumentar ao longo das Ã©pocas
  - ğŸ¯ Meta: > 80%

- **Validation Accuracy**: PrecisÃ£o em dados nÃ£o vistos
  - â¬†ï¸ Deve aumentar (mais importante que training)
  - ğŸ¯ Meta: > 75%

#### **ğŸ“Š Learning Rate**
- ğŸ“ˆ Como a taxa de aprendizagem muda
- ğŸ”§ ReduceLROnPlateau: diminui quando loss para de melhorar

### ğŸ§  GRAPHS (Arquitetura)

#### **ğŸ—ï¸ Estrutura do Modelo**
- **Input Layer**: 39 features neuroimagem
- **Hidden Layers**: 256 â†’ 128 â†’ 64 â†’ 32 â†’ 16 neurons
- **Output Layer**: 1 (binÃ¡rio) ou 4 (CDR) neurons
- **Activations**: ReLU (hidden), Sigmoid/Softmax (output)
- **Regularization**: Dropout + BatchNormalization

### âš¡ PROFILER (Performance GPU)

#### **ğŸš€ GPU Performance**
- **Device Utilization**: % uso da GPU
  - ğŸ¯ Meta: > 80% durante treinamento
  - âš ï¸ Se < 50% = gargalo CPU/I-O

- **Memory Usage**: Uso de VRAM
  - ğŸ“Š Atual: ~2MB (muito eficiente!)
  - ğŸ’¾ RTX A4000: 16GB disponÃ­vel

- **Step Time**: Tempo por batch
  - âš¡ GPU: ~48-300ms por step
  - ğŸŒ CPU seria: ~1-3s por step

### ğŸ“Š HISTOGRAMS (DistribuiÃ§Ã£o)

#### **âš–ï¸ Weights Distribution**
- ğŸ“Š Como os pesos estÃ£o distribuÃ­dos
- âœ… Boa distribuiÃ§Ã£o: gaussiana centrada em 0
- âŒ Problema: todos zeros ou muito grandes

#### **ğŸ“ˆ Gradients**
- ğŸ”„ Como os gradientes fluem na rede
- âœ… Bom: valores pequenos mas nÃ£o zero
- âŒ Vanishing: muito prÃ³ximos de zero
- âŒ Exploding: valores muito grandes

## ğŸ¨ VISUALIZAÃ‡Ã•ES ESPECÃFICAS DO SEU PROJETO

### ğŸ§  Classificador BinÃ¡rio (Demented/Non-demented)
```
ğŸ“Š MÃ©tricas Finais:
- Training Accuracy: 93.8%
- Validation Accuracy: 75.0%
- AUC Score: 0.736
- Ã‰pocas: 50
- Tempo: 18.2s
```

### ğŸ¯ Classificador CDR (0, 0.5, 1, 2)
```
ğŸ“Š MÃ©tricas Finais:
- Training Accuracy: 82.5%
- Validation Accuracy: 85.0%
- Classes: 4 (CDR levels)
- Ã‰pocas: 50
- Tempo: 18.3s
```

## ğŸ”§ DICAS DE ANÃLISE

### âœ… Sinais de Bom Treinamento:
- ğŸ“‰ Loss diminuindo suavemente
- ğŸ“ˆ Accuracy aumentando consistentemente
- ğŸ¯ DiferenÃ§a training/validation < 10%
- âš¡ GPU utilization > 80%

### âš ï¸ Sinais de Problemas:
- ğŸ“ˆ Loss aumentando ou oscilando muito
- ğŸ”„ Training accuracy muito maior que validation
- ğŸŒ GPU utilization < 50%
- ğŸ’¥ Gradientes exploding/vanishing

### ğŸ›ï¸ Ajustes Recomendados:
- **Overfitting**: Aumentar dropout, reduzir modelo
- **Underfitting**: Diminuir dropout, aumentar modelo
- **Slow convergence**: Aumentar learning rate
- **Instability**: Diminuir learning rate

## ğŸ‰ RECURSOS AVANÃ‡ADOS

### ğŸ“¸ Export de Dados:
```bash
# Salvar grÃ¡ficos como imagem
Download â†’ PNG

# Exportar dados como CSV
Download â†’ CSV
```

### ğŸ”„ Comparar Experimentos:
- Upload mÃºltiplos runs
- Comparar side-by-side
- Analisar hyperparameters

### â±ï¸ Real-time Monitoring:
- Auto-refresh a cada 30s
- Monitorar treinamentos longos
- Parar early se necessÃ¡rio 